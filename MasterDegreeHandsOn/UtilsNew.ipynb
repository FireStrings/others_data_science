{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0b537ac-4cb6-4015-b700-3d8ffe7e1336",
   "metadata": {},
   "source": [
    "### Libs import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8efb8f7-2e74-4897-9d6a-950b9238505a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from scipy.special import expit\n",
    "from scipy.stats import zscore\n",
    "from pandas.errors import SettingWithCopyWarning\n",
    "import os\n",
    "import io\n",
    "from os import listdir\n",
    "from os import system\n",
    "import subprocess\n",
    "from functools import reduce\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import statsmodels.tsa.stattools as ts\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=SettingWithCopyWarning)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45b86e7-c1f5-446a-a8ec-cdb60bd40d00",
   "metadata": {},
   "source": [
    "### Aux methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f454a7a6-7ece-410e-942d-7dac4a75418b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_num_rows_cols(nr, nc):\n",
    "    pd.set_option('display.max_columns', nc)\n",
    "    pd.set_option('display.max_rows', nr)\n",
    "\n",
    "def set_size_plot(x, y):\n",
    "    sns.set_theme(rc={'figure.figsize':(x, y)})\n",
    "    \n",
    "def getSigmoid():\n",
    "    arr = np.arange(0, 1, 0.02)\n",
    "    np.hstack(np.vstack(arr))\n",
    "    def sigmoid(x):\n",
    "        return 1/(1+expit(-x))\n",
    "    \n",
    "    sigmoid(arr)\n",
    "    sns.scatterplot(x=arr, y=sigmoid(arr))\n",
    "\n",
    "def get_files(n=1, lazy=True):\n",
    "    cwd = os.getcwd()\n",
    "\n",
    "    base_path = \"data/estacoes_solares/2023/\"\n",
    "    dict_data = {}\n",
    "    list_files = [x for x in listdir(cwd + \"/\" + base_path) if \".csv\" in x.lower()]    \n",
    "\n",
    "    if n:\n",
    "        _range = list_files[0:n]\n",
    "    else:\n",
    "        _range = list_files\n",
    "    \n",
    "    for i in _range:\n",
    "        # print(\"Processando arquivo \" + i)\n",
    "        code = i.split(\"_\")[3]\n",
    "        \n",
    "        cmd = [\"head\", \"-8\", cwd+ \"/\" + base_path + i]\n",
    "        p = subprocess.Popen(cmd, stdout=subprocess.PIPE)\n",
    "        \n",
    "        result = p.communicate()\n",
    "        head = result[0].decode('ISO-8859-1')\n",
    "\n",
    "        if lazy:\n",
    "            data = base_path + i\n",
    "        else:\n",
    "            data = pd.read_csv(base_path+i, sep=\";\", skiprows=10)\n",
    "        \n",
    "        dict_data[code] = [head, data]\n",
    "\n",
    "    return dict_data\n",
    "\n",
    "def getDictToRenameDataFrame(list_columns):\n",
    "    list_columns_new = []\n",
    "    for i in list_columns: \n",
    "        list_columns_new.append(str\n",
    "              .lower(i)\n",
    "              .replace(\" \", \"_\")\n",
    "              . replace(\"(\", \"_\")\n",
    "              .replace(\")\", \"\")\n",
    "              .replace(\"/\", \"\")\n",
    "              .replace(\"²\", \"2\")\n",
    "              .replace(\"°\", \"\")\n",
    "              .replace(\"%\", \"perc\")\n",
    "              .replace(\"._\", \"_\")\n",
    "              .replace(\".\", \"_\")\n",
    "              .replace(\"__\", \"_\")\n",
    "              .replace(\"_-_\", \"_\")\n",
    "              .replace(\",_\", \"_\")\n",
    "             )\n",
    "    \n",
    "    return dict(zip(list_columns, list_columns_new))\n",
    "\n",
    "def cols_standardization(df):\n",
    "    list_columns = df.columns\n",
    "\n",
    "    list_dict_to_rename = getDictToRenameDataFrame(list_columns)\n",
    "    \n",
    "    return df.rename(columns=list_dict_to_rename).rename(columns={\"radiacao_kjm2\": \"radiacao\"})\n",
    "\n",
    "def hour_transform(n):\n",
    "    if len(str(n)) == 4:\n",
    "        return str(n)[0:2] + \":\" + str(n)[2:] + \":00\"\n",
    "    elif len(str(n)) == 3:\n",
    "        return \"0\" + str(n)[0:1] + \":\" + str(n)[1:] + \":00\"\n",
    "    elif n == 0:\n",
    "        return \"00:00:00\"\n",
    "\n",
    "def create_datetime_feature(df):\n",
    "    df[\"hora_medicao\"] = df[\"hora_medicao\"].apply(hour_transform)\n",
    "    df[\"data_hora_str\"] = df[\"data_medicao\"] + \" \" + df[\"hora_medicao\"]\n",
    "    df[\"data_hora\"] = pd.to_datetime(df[\"data_hora_str\"], format=\"%d-%m-%Y %H:%M:%S\")\n",
    "    df[\"data\"] = pd.to_datetime(df[\"data_medicao\"], format=\"%d-%m-%Y\")\n",
    "    df[\"data_str\"] = df[\"data_hora_str\"].str.split().str[0]\n",
    "    df[\"hora\"] = df['data_hora'].dt.hour\n",
    "    \n",
    "    return df.drop([\"data_hora_str\", \"data_medicao\", \"hora_medicao\"], axis=1)\n",
    "    \n",
    "def transform_datetime(df):\n",
    "    df[\"data_medicao\"] = df[\"data\"].str.replace('/', '-', regex=False)\n",
    "    df[\"hora_medicao\"] = df[\"hora_utc\"].astype(\"str\").str.replace(' UTC', '', regex=False).astype('int32')\n",
    "    return df.drop([\"data\", \"hora_utc\"], axis=1)\n",
    "    \n",
    "def create_split_date_features(df):\n",
    "    df[\"dia\"] = df[\"data_hora\"].dt.day\n",
    "    df[\"mes\"] = df[\"data_hora\"].dt.month\n",
    "    df[\"ano\"] = df[\"data_hora\"].dt.year\n",
    "\n",
    "    return df\n",
    "\n",
    "def create_category(column, df):\n",
    "    labels = [\"A\", \"B\", \"C\", \"D\"]\n",
    "    classes = df.describe()[column][3:8].values\n",
    "\n",
    "    if classes[1] == 0:\n",
    "        classes[1] = classes[1]+0.1\n",
    "        print(\"aqui\")\n",
    "    print(classes)\n",
    "    \n",
    "    return pd.cut(x = df[column],\n",
    "         bins = classes,\n",
    "         labels = labels,\n",
    "         include_lowest = True)\n",
    "\n",
    "def removeNulls(df, col):\n",
    "    return df[df[col].notnull()]\n",
    "\n",
    "def pre_processing(raw_df):\n",
    "    df = cols_standardization(raw_df)\n",
    "    df = transform_datetime(df)\n",
    "    df = create_datetime_feature(df)\n",
    "    df = create_split_date_features(df)\n",
    "    df = removeNulls(df, \"radiacao\")\n",
    "    df = change_types(df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def reduce_df(list_df, key):\n",
    "    if not key:\n",
    "        return reduce(lambda x, y: pd.merge(x, y), list_df)\n",
    "        \n",
    "    return reduce(lambda x, y: pd.merge(x, y, on = key), list_df)\n",
    "\n",
    "def load(path):\n",
    "    return pd.read_csv(path, sep=\";\", encoding = \"ISO-8859-1\", skiprows=8)\n",
    "\n",
    "def get_perc_nulls(df):\n",
    "    return (df.isnull().sum()/(len(df)))*100\n",
    "\n",
    "def get_percentils(df, col):\n",
    "    for i in range(0, 101):\n",
    "        value_str = str(i)\n",
    "    \n",
    "        if len(value_str) == 1:\n",
    "            value_str = \"0.0\"+value_str\n",
    "        \n",
    "        elif len(value_str) == 2:\n",
    "            value_str = \"0.\"+value_str\n",
    "        else:\n",
    "            value_str = \"1.0\"\n",
    "        \n",
    "        double_value = float(value_str) \n",
    "        print(value_str, df[col].quantile(double_value))\n",
    "\n",
    "def plot_by_col(df, col_grouped, col_target):\n",
    "    df = df[[col_grouped, col_target]].groupby([col_grouped]).mean().reset_index()\n",
    "    \n",
    "    sns.lineplot(data=df, x=df[col_grouped], y=df[col_target])\n",
    "\n",
    "def plot_by_range(df, col_x, col_y, dt_start, dt_end):\n",
    "    df = filter_between(df, col_x, dt_start, dt_end)\n",
    "    \n",
    "    sns.lineplot(data=df, x=df[col_x], y=df[col_y])\n",
    "\n",
    "def filter_between(df, col, value_1, value_2):\n",
    "    _filter = (df[col] >= value_1) & (df[col] <= value_2)\n",
    "    return df[_filter]\n",
    "\n",
    "def set_plot_size(x, y):\n",
    "    sns.set_theme(rc={'figure.figsize':(x,y)})\n",
    "\n",
    "def change_types(df):\n",
    "    list_columns = df.drop(\"data_str\", axis=1).columns\n",
    "\n",
    "    for i in list_columns:\n",
    "        if 'object' in df[i].dtypes.name:\n",
    "            df[i] = df[i].str.replace(\",\", \".\").astype('float64')\n",
    "            \n",
    "        else:\n",
    "            continue\n",
    "           \n",
    "        \n",
    "    return df\n",
    "\n",
    "def treat_columns(df):\n",
    "\n",
    "    columns_to_drop = ['pressão_atmosferica_max_na_hora_ant_aut_mb',\n",
    "                       'pressão_atmosferica_min_na_hora_ant_aut_mb', \n",
    "                       'temperatura_do_ponto_de_orvalho_c',\n",
    "                       'temperatura_máxima_na_hora_ant_aut_c',\n",
    "                       'temperatura_mínima_na_hora_ant_aut_c',\n",
    "                       'temperatura_orvalho_max_na_hora_ant_aut_c',\n",
    "                       'temperatura_orvalho_min_na_hora_ant_aut_c',\n",
    "                       'umidade_rel_max_na_hora_ant_aut_perc',\n",
    "                       'umidade_rel_min_na_hora_ant_aut_perc',\n",
    "                      'vento_direção_horaria_gr__gr',\n",
    "                      'vento_rajada_maxima_ms']\n",
    "\n",
    "    columns_to_rename = {'precipitação_total_horário_mm': 'precipitacao',\n",
    "                        'pressao_atmosferica_ao_nivel_da_estacao_horaria_mb': 'press_atmo',\n",
    "                        'temperatura_do_ar_bulbo_seco_horaria_c': 'temperatura',\n",
    "                        'umidade_relativa_do_ar_horaria_perc': 'umidade',\n",
    "                         'vento_velocidade_horaria_ms':'vento_velocidade_horaria'}\n",
    "\n",
    "    return df.rename(columns=columns_to_rename).drop(columns_to_drop, axis=1)\n",
    "\n",
    "def my_autocov(df, col, interval=1):\n",
    "    serie = np.array(df[col].to_list())\n",
    "\n",
    "    # serie = np.array([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20])\n",
    "    \n",
    "    xt = serie[:-interval]\n",
    "    xt1 = serie[interval:]\n",
    "    n_pairs = len(xt)\n",
    "\n",
    "    mean_xt = xt.sum(axis=0)/n_pairs\n",
    "    mean_xt1 = xt1.sum(axis=0)/n_pairs\n",
    "\n",
    "    dev_xt = xt - mean_xt\n",
    "    dev_xt1 = xt1 - mean_xt1\n",
    "\n",
    "    d = {\"xt\": xt, \"xt1\": xt1}\n",
    "    df_new = pd.DataFrame(data=d)\n",
    "\n",
    "    sns.scatterplot(df_new, x=\"xt\", y=\"xt1\")\n",
    "\n",
    "    return dev_xt.dot(dev_xt1)/n_pairs\n",
    "\n",
    "def plot_distrib_horario(df):\n",
    "    local_anual_df = df[[\"data_hora\", \"radiacao\", \"temp_ins_c\"]]\n",
    "    local_anual_df[\"hora\"] = local_anual_df[\"data_hora\"].dt.hour\n",
    "    \n",
    "    local_anual_df = local_anual_df[[\"hora\", \"radiacao\"]].groupby(['hora']).mean().reset_index()\n",
    "    \n",
    "    plot = sns.barplot(local_anual_df, x=\"hora\", y=\"radiacao\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ae699b-f0c0-4b87-8ffa-be66c07a7430",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
